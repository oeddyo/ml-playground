{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check for MPS (Apple Silicon GPU) availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252777 252777\n",
      "len =  252777 252777\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "hidden_size = 1000\n",
    "PAD = \"<PAD>\"\n",
    "EOS = \"<EOS>\"\n",
    "\n",
    "def read_data():\n",
    "    s_lines = open(\"news-commentary-v13.zh-en.en\", 'r').readlines()\n",
    "    t_lines = open(\"news-commentary-v13.zh-en.zh\", 'r').readlines()\n",
    "\n",
    "    print(len(s_lines), len(t_lines))\n",
    "    assert len(s_lines) == len(t_lines), \"src target lines not matching\"\n",
    "    return s_lines, t_lines\n",
    "\n",
    "def create_voc(lines, is_target=False):\n",
    "    if is_target:\n",
    "        lines = [[EOS] + list(line) for line in lines]\n",
    "    else:\n",
    "        lines = [list(line) for line in lines]\n",
    "\n",
    "    voc = set()\n",
    "    for line in lines:\n",
    "        for c in line:\n",
    "            voc.add(c)\n",
    "\n",
    "    voc = sorted(list(voc))\n",
    "    voc = [PAD] + voc\n",
    "\n",
    "    itoc, ctoi = {}, {}\n",
    "    for i, c in enumerate(voc):\n",
    "        itoc[i] = c\n",
    "        ctoi[c] = i\n",
    "\n",
    "    res = []\n",
    "    for line in lines:\n",
    "        cur = []\n",
    "        for c in line:\n",
    "            cur.append(ctoi[c])\n",
    "\n",
    "        res.append(cur)\n",
    "\n",
    "    return res, itoc, ctoi\n",
    "\n",
    "ss, ts = read_data()\n",
    "\n",
    "source, source_itoc, _ = create_voc(ss)\n",
    "target, target_itoc, _ = create_voc(ts, True)\n",
    "\n",
    "source_voc_size = len(source_itoc)\n",
    "target_voc_size = len(target_itoc)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    source_batch, target_batch = zip(*batch)\n",
    "    source_padded = pad_sequence([torch.tensor(s) for s in source_batch], padding_value=0)  # Assuming 0 is the PAD index\n",
    "    target_padded = pad_sequence([torch.tensor(t) for t in target_batch], padding_value=0)\n",
    "    return source_padded, target_padded\n",
    "\n",
    "class MTDataset(Dataset):\n",
    "    def __init__(self, source, target):\n",
    "        print(\"len = \", len(source), len(target))\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.source[item], self.target[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "\n",
    "batch_size = 32\n",
    "training_loader = DataLoader(MTDataset(source, target), batch_size=batch_size, collate_fn=collate_fn, drop_last=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '\\t', 2: '\\n', 3: ' ', 4: '!', 5: '\"', 6: '#', 7: '$', 8: '%', 9: '&', 10: \"'\", 11: '(', 12: ')', 13: '*', 14: '+', 15: ',', 16: '-', 17: '.', 18: '/', 19: '0', 20: '1', 21: '2', 22: '3', 23: '4', 24: '5', 25: '6', 26: '7', 27: '8', 28: '9', 29: ':', 30: ';', 31: '=', 32: '?', 33: '@', 34: 'A', 35: 'B', 36: 'C', 37: 'D', 38: 'E', 39: 'F', 40: 'G', 41: 'H', 42: 'I', 43: 'J', 44: 'K', 45: 'L', 46: 'M', 47: 'N', 48: 'O', 49: 'P', 50: 'Q', 51: 'R', 52: 'S', 53: 'T', 54: 'U', 55: 'V', 56: 'W', 57: 'X', 58: 'Y', 59: 'Z', 60: '[', 61: '\\\\', 62: ']', 63: '_', 64: '`', 65: 'a', 66: 'b', 67: 'c', 68: 'd', 69: 'e', 70: 'f', 71: 'g', 72: 'h', 73: 'i', 74: 'j', 75: 'k', 76: 'l', 77: 'm', 78: 'n', 79: 'o', 80: 'p', 81: 'q', 82: 'r', 83: 's', 84: 't', 85: 'u', 86: 'v', 87: 'w', 88: 'x', 89: 'y', 90: 'z', 91: '\\x80', 92: '\\x91', 93: '\\x9d', 94: '\\xa0', 95: '£', 96: '¥', 97: '\\xad', 98: '°', 99: '±', 100: '´', 101: '·', 102: 'º', 103: '¼', 104: 'Á', 105: 'Ã', 106: 'Å', 107: 'Ç', 108: 'É', 109: 'Í', 110: 'Î', 111: 'Ò', 112: 'Ó', 113: 'Ö', 114: 'Ü', 115: 'à', 116: 'á', 117: 'â', 118: 'ã', 119: 'ä', 120: 'å', 121: 'æ', 122: 'ç', 123: 'è', 124: 'é', 125: 'ê', 126: 'ë', 127: 'í', 128: 'î', 129: 'ï', 130: 'ð', 131: 'ñ', 132: 'ó', 133: 'ô', 134: 'õ', 135: 'ö', 136: 'ø', 137: 'ú', 138: 'ü', 139: 'ă', 140: 'ą', 141: 'ć', 142: 'Č', 143: 'č', 144: 'ē', 145: 'ę', 146: 'ğ', 147: 'İ', 148: 'ı', 149: 'ł', 150: 'ń', 151: 'ō', 152: 'ő', 153: 'œ', 154: 'ś', 155: 'ş', 156: 'Š', 157: 'š', 158: 'ū', 159: 'ű', 160: 'ż', 161: 'Ž', 162: 'ž', 163: 'ȃ', 164: 'ș', 165: '˚', 166: 'Φ', 167: 'Χ', 168: 'ε', 169: 'ứ', 170: '\\u200e', 171: '‑', 172: '‒', 173: '–', 174: '—', 175: '‘', 176: '’', 177: '“', 178: '”', 179: '•', 180: '…', 181: '\\u2028', 182: '⁰', 183: '₂', 184: '€', 185: '™', 186: '−', 187: '≤', 188: '危', 189: '城', 190: '市', 191: '机', 192: '％', 193: '�'}\n"
     ]
    }
   ],
   "source": [
    "print(source_itoc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([20, 50, 35, 54, 54, 39, 40, 49, 43, 59, 54, 35, 43, 40, 49, 40, 36, 53,\n",
      "        39, 59, 43, 35, 49, 40, 36, 57, 57, 35, 54, 57, 57, 36]) tensor([  19, 1366,  233, 1114, 2834, 2223, 2567, 1463,  299, 2567,  252, 3275,\n",
      "          19, 1268, 1463, 4475,  242,  517, 2258, 3275, 3245,  391, 1658,  335,\n",
      "         381,  406, 1463, 4048,   19, 1658,   20,  373])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x,y in training_loader:\n",
    "    print(x[0], y[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TranslateModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.source_embedding = nn.Embedding(source_voc_size, hidden_size)\n",
    "        self.target_embedding = nn.Embedding(target_voc_size, hidden_size)\n",
    "\n",
    "        self.encoder = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "        self.decoder = nn.LSTM(target_voc_size, hidden_size, num_layers=2)\n",
    "        self.linear = nn.Linear(hidden_size, target_voc_size)\n",
    "    def forward(self, source_sentences, target_sentences):\n",
    "        #return self.encoder(x)\n",
    "\n",
    "        emb = self.source_embedding(source_sentences)\n",
    "        _, (h, c) = self.encoder(emb)\n",
    "\n",
    "\n",
    "        output = self.decoder(self.target_embedding(target_sentences), (h, c))\n",
    "\n",
    "\n",
    "        return self.linear(output)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TranslateModel.forward() missing 1 required positional argument: 'target_sentences'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m train_x, train_y \u001B[38;5;241m=\u001B[39m train_x\u001B[38;5;241m.\u001B[39mto(device), train_y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     17\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 19\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(r, train_y)\n\u001B[1;32m     22\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "\u001B[0;31mTypeError\u001B[0m: TranslateModel.forward() missing 1 required positional argument: 'target_sentences'"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "model = TranslateModel().to(device)\n",
    "\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer= Adam(model.parameters(), lr=1)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    print(\"epoch\", epoch)\n",
    "    for train_x, train_y in training_loader:\n",
    "        train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        r = model.forward(train_x, train_y)\n",
    "\n",
    "        loss = criterion(r, train_y)\n",
    "        loss.backward()\n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        norm = clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
